{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"hw04.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task description\n- Classify the speakers of given features.\n- Main goal: Learn how to use transformer.\n- Baselines:\n  - Easy: Run sample code and know how to use transformer.\n  - Medium: Know how to adjust parameters of transformer.\n  - Strong: Construct [conformer](https://arxiv.org/abs/2005.08100) which is a variety of transformer. \n  - Boss: Implement [Self-Attention Pooling](https://arxiv.org/pdf/2008.01077v1.pdf) & [Additive Margin Softmax](https://arxiv.org/pdf/1801.05599.pdf) to further boost the performance.\n\n- Other links\n  - Kaggle: [link](https://www.kaggle.com/t/ac77388c90204a4c8daebeddd40ff916)\n  - Slide: [link](https://docs.google.com/presentation/d/1HLAj7UUIjZOycDe7DaVLSwJfXVd3bXPOyzSb6Zk3hYU/edit?usp=sharing)\n  - Data: [link](https://drive.google.com/drive/folders/1vI1kuLB-q1VilIftiwnPOCAeOOFfBZge?usp=sharing)\n\n# Download dataset\n- Data is [here](https://drive.google.com/drive/folders/1vI1kuLB-q1VilIftiwnPOCAeOOFfBZge?usp=sharing)","metadata":{"id":"C_jdZ5vHJ4A9"}},{"cell_type":"markdown","source":"## Fix Random Seed","metadata":{"id":"ENWVAUDVJtVY"}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport random\n\ndef set_seed(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nset_seed(2023)\nkfold = 8","metadata":{"id":"E6burzCXIyuA","execution":{"iopub.status.busy":"2023-03-21T06:24:01.586163Z","iopub.execute_input":"2023-03-21T06:24:01.586556Z","iopub.status.idle":"2023-03-21T06:24:03.214965Z","shell.execute_reply.started":"2023-03-21T06:24:01.586476Z","shell.execute_reply":"2023-03-21T06:24:03.213988Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data\n\n## Dataset\n- Original dataset is [Voxceleb2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html).\n- The [license](https://creativecommons.org/licenses/by/4.0/) and [complete version](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/license.txt) of Voxceleb2.\n- We randomly select 600 speakers from Voxceleb2.\n- Then preprocess the raw waveforms into mel-spectrograms.\n\n- Args:\n  - data_dir: The path to the data directory.\n  - metadata_path: The path to the metadata.\n  - segment_len: The length of audio segment for training. \n- The architecture of data directory  \n  - data directory  \n  |---- metadata.json  \n  |---- testdata.json  \n  |---- mapping.json  \n  |---- uttr-{random string}.pt\n\n- The information in metadata\n  - \"n_mels\": The dimention of mel-spectrogram.\n  - \"speakers\": A dictionary. \n    - Key: speaker ids.\n    - value: \"feature_path\" and \"mel_len\"\n\n\nFor efficiency, we segment the mel-spectrograms into segments in the traing step.","metadata":{"id":"k7dVbxW2LASN"}},{"cell_type":"code","source":"import os\nimport json\nimport torch\nimport random\nfrom pathlib import Path\nfrom torch.utils.data import Dataset\nfrom torch.nn.utils.rnn import pad_sequence\n\nclass VoxDataset(Dataset):\n    def __init__(self, data_dir, segment_len=512):\n        self.training = False\n        self.data_dir = data_dir\n        self.segment_len = segment_len\n        self.p = 0.95\n        print(f\"dataset configs: segment_len={segment_len}, p={self.p}\")\n    \n        # Load the mapping from speaker neme to their corresponding id. \n        mapping_path = Path(data_dir) / \"mapping.json\"\n        mapping = json.load(mapping_path.open())\n        self.speaker2id = mapping[\"speaker2id\"]\n    \n        # Load metadata of training data.\n        metadata_path = Path(data_dir) / \"metadata.json\"\n        metadata = json.load(open(metadata_path))[\"speakers\"]\n    \n        # Get the total number of speaker.\n        self.speaker_num = len(metadata.keys())\n        self.data = []\n        for speaker in metadata.keys():\n            for utterances in metadata[speaker]:\n                self.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n \n    def __len__(self):\n            return len(self.data)\n \n    def __getitem__(self, index):\n        feat_path, speaker = self.data[index]\n        # Load preprocessed mel-spectrogram.\n        mel = torch.load(os.path.join(self.data_dir, feat_path))\n\n        if len(mel) > self.segment_len:\n            start = random.randint(0, len(mel) - self.segment_len)\n            mel = torch.FloatTensor(mel[start:start + self.segment_len])\n        else:\n            mel = torch.FloatTensor(mel)\n        \n        if self.training is True:\n            seglen, speclen = mel.shape\n            ptime = random.uniform(0, self.p)\n            pspec = random.uniform(0, self.p)\n            time_mask_len = int(seglen * ptime)\n            time_mask_beg = random.randint(0, seglen - time_mask_len)\n            spec_mask_len = int(speclen * pspec)\n            spec_mask_beg = random.randint(0, speclen)\n            mel[time_mask_beg:time_mask_beg + time_mask_len, :] = 0\n            if spec_mask_beg + spec_mask_len < speclen:\n                mel[:, spec_mask_beg:spec_mask_beg + spec_mask_len] = 0\n            else:\n                mel[:, spec_mask_beg:speclen] = 0\n                mel[:, 0:spec_mask_len - (speclen - spec_mask_beg)] = 0\n        \n        # Turn the speaker id into long for computing loss later.\n        speaker = torch.FloatTensor([speaker]).long()\n        return mel, speaker\n \n    def get_speaker_number(self):\n        return self.speaker_num","metadata":{"id":"KpuGxl4CI2pr","execution":{"iopub.status.busy":"2023-03-21T06:24:03.217564Z","iopub.execute_input":"2023-03-21T06:24:03.218426Z","iopub.status.idle":"2023-03-21T06:24:03.232011Z","shell.execute_reply.started":"2023-03-21T06:24:03.218388Z","shell.execute_reply":"2023-03-21T06:24:03.231075Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader\n- Split dataset into training dataset(90%) and validation dataset(10%).\n- Create dataloader to iterate the data.","metadata":{"id":"668hverTMlGN"}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.nn.utils.rnn import pad_sequence\n\n\ndef collate_batch(batch):\n    # Process features within a batch.\n    \"\"\"Collate a batch of data.\"\"\"\n    mel, speaker = zip(*batch)\n    # Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n    mel = pad_sequence(mel, batch_first=True, padding_value=-20)    # pad log 10^(-20) which is very small value.\n    # mel: (batch size, length, 40)\n    return mel, torch.FloatTensor(speaker).long()\n\n\ndef get_dataloader(data_dir, batch_size, n_workers):\n    \"\"\"Generate dataloader\"\"\"\n    dataset = VoxDataset(data_dir)\n    speaker_num = dataset.get_speaker_number()\n    # Split dataset into training dataset and validation dataset\n    proportions = [1. / kfold for i in range(kfold)]\n    lengths = [int(p * len(dataset)) for p in proportions]\n    lengths[-1] = len(dataset) - sum(lengths[:-1])\n    sets = random_split(dataset, lengths, generator=torch.Generator().manual_seed(2023))\n\n    for trainset in sets:\n        trainset.training = True\n    train_loader = [DataLoader(\n            trainset,\n            batch_size=batch_size,\n            shuffle=True,\n            drop_last=True,\n            num_workers=n_workers,\n            pin_memory=True,\n            collate_fn=collate_batch,\n        ) for trainset in sets]\n\n    for validset in sets:\n        validset.training = False\n    valid_loader = [DataLoader(\n            validset,\n            batch_size=batch_size,\n            num_workers=n_workers,\n            drop_last=True,\n            pin_memory=True,\n            collate_fn=collate_batch,\n        ) for validset in sets]\n\n    return train_loader, valid_loader, speaker_num","metadata":{"id":"B7c2gZYoJDRS","execution":{"iopub.status.busy":"2023-03-21T06:24:03.233256Z","iopub.execute_input":"2023-03-21T06:24:03.236322Z","iopub.status.idle":"2023-03-21T06:24:03.247503Z","shell.execute_reply.started":"2023-03-21T06:24:03.236282Z","shell.execute_reply":"2023-03-21T06:24:03.246231Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Model\n- TransformerEncoderLayer:\n  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n  - Parameters:\n    - embed: the number of expected features of the input (required).\n    - nhead: the number of heads of the multiheadattention models (required).\n    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n    - dropout: the dropout value (default=0.1).\n    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n\n- TransformerEncoder:\n  - TransformerEncoder is a stack of N transformer encoder layers\n  - Parameters:\n    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n    - num_layers: the number of sub-encoder-layers in the encoder (required).\n    - norm: the layer normalization component (optional).","metadata":{"id":"5FOSZYxrMqhc"}},{"cell_type":"code","source":"## import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass SubSampling(nn.Module):\n    def __init__(self, in_channel=1, out_channel=3):\n        super(SubSampling, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(in_channel, out_channel, kernel_size=5, stride=2, padding=2),\n            nn.ReLU(),\n        )\n    def forward(self, x):\n        outputs = self.model(x.unsqueeze(1))\n        batch_size, c, seqlen, width = outputs.size()\n        outputs = outputs.permute(0, 2, 1, 3)\n        outputs = outputs.contiguous().view(batch_size, seqlen, c * width)\n        return outputs\n\nclass Perm(nn.Module):\n    def __init__(self, order):\n        super(Perm, self).__init__()\n        self.order = order\n    def forward(self, x):\n        return x.permute(*self.order)\n\nclass FFN(nn.Module):\n    def __init__(self, embed, dropout):\n        super(FFN, self).__init__()\n        # inout: (batch_size, seqlen, embed)\n        self.model = nn.Sequential(\n            nn.LayerNorm(embed),\n            nn.Linear(embed, embed * 4),\n            nn.SiLU(),\n            nn.Dropout(dropout),\n            nn.Linear(embed * 4, embed),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x):\n        out = self.model(x)\n        return out + x\n\nclass PointwiseConv(nn.Module):\n    def __init__(self, in_channel, out_channel):\n        # (batch, c, seq)\n        super(PointwiseConv, self).__init__()\n        self.model = nn.Conv1d(in_channel, out_channel, kernel_size=1, stride=1, padding=0)\n    def forward(self, x):\n        return self.model(x)\n\nclass DepthwiseConv(nn.Module):\n    def __init__(self, in_channel, out_channel, kernel_size):\n        # (batch, c, seq)\n        print(f\"depwise_conv config: kernel_size={kernel_size}\")\n        super(DepthwiseConv, self).__init__()\n        assert out_channel % in_channel == 0\n        padding = (kernel_size - 1) // 2\n        self.model = nn.Conv1d(in_channel, out_channel, kernel_size=kernel_size,\n                               stride=1, padding=padding, groups=in_channel)\n    def forward(self, x):\n        return self.model(x)\n\nclass ConvBlock(nn.Module):\n    def __init__(self, embed, dropout):\n        super(ConvBlock, self).__init__()\n        # inout: (batch, seq, embed)\n        self.model = nn.Sequential(\n            nn.LayerNorm(embed),                                  # out: (batch, seq, embed)\n            Perm((0, 2, 1)),                                        # out: (batch, embed, seq)\n            PointwiseConv(in_channel=embed, out_channel=embed * 2), # out: (batch, embed * 2, seq)\n            nn.GLU(dim=1),\n            DepthwiseConv(in_channel=embed, out_channel=embed, kernel_size=9),     # inout: (batch, embed, seq)\n            nn.BatchNorm1d(embed),\n            nn.SiLU(),\n            PointwiseConv(in_channel=embed, out_channel=embed),\n            nn.Dropout(dropout),\n            Perm((0, 2, 1))                                         # out: (batch, seq, embed)\n        )\n    def forward(self, x):\n        out = self.model(x)\n        return out + x\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, embed, num_heads, dropout):\n        super(MultiHeadAttention, self).__init__()\n        self.layernorm = nn.LayerNorm(embed)\n        self.attention = nn.MultiheadAttention(embed, num_heads, dropout=dropout, batch_first=True)\n    def forward(self, x, mask=None):\n        xx = self.layernorm(x)\n        out, _ = self.attention(xx, xx, xx, need_weights=False)\n        return out + x\n\nclass ConformerBlock(nn.Module):\n    def __init__(self, embed, dropout):\n        super(ConformerBlock, self).__init__()\n        self.model = nn.Sequential(\n            FFN(embed=embed, dropout=dropout),\n            MultiHeadAttention(embed=embed, num_heads=8, dropout=dropout),\n            ConvBlock(embed=embed, dropout=dropout),\n            FFN(embed=embed, dropout=dropout),\n            nn.LayerNorm(embed)\n        )\n    def forward(self, x):\n        return self.model(x)\n\nclass AdditiveMarginSoftmax(nn.Module):\n    def __init__(self, embed, n_spks):\n        super(AdditiveMarginSoftmax, self).__init__()\n        self.margin = 0.35\n        self.factor = 30\n        self.n_spks = n_spks\n        self.W = torch.nn.Parameter(torch.randn(embed, n_spks), requires_grad=True)\n        nn.init.xavier_normal_(self.W, gain=1)\n    def forward(self, x, y=None):\n        norm_x = torch.norm(x, dim=1, p=2, keepdim=True).clamp(min=1e-12)\n        x_norm = torch.div(x, norm_x)\n        norm_W = torch.norm(self.W, dim=0, p=2, keepdim=True).clamp(min=1e-12)\n        W_norm = torch.div(self.W, norm_W)\n        out = torch.mm(x_norm, W_norm)\n        sub = torch.zeros_like(out)\n        if (y != None):\n            sub = sub.scatter_(1, y.view(-1, 1), self.margin)\n        out = self.factor * (out - sub)\n        return out\n\nclass SelfAttentionPooling(nn.Module):\n    def __init__(self, input_dim):\n        super(SelfAttentionPooling, self).__init__()\n        self.W = nn.Linear(input_dim, 1)\n    def forward(self, batch_rep):\n        att_w = F.softmax(self.W(batch_rep).squeeze(-1), dim=-1).unsqueeze(-1)\n        utter_rep = torch.sum(batch_rep * att_w, dim=1)\n        return utter_rep\n\nclass Classifier(nn.Module):\n    def __init__(self, feat=40, embed=256, n_spks=600, dropout=0.3):\n        print(f\"running config: embed={embed}, dropout={dropout}\")\n        super().__init__()\n        subsample_expand = 4\n        subsample_feat = (feat + 1) // 2\n        \n        self.model = nn.Sequential(\n            SubSampling(in_channel=1, out_channel=subsample_expand), # out: (batch, seq, feat * channel)\n            nn.Linear(subsample_feat * subsample_expand, embed),\n            #nn.Linear(feat, embed),\n            nn.Dropout(dropout),\n            ConformerBlock(embed=embed, dropout=dropout),\n            SelfAttentionPooling(embed),                   # out: (batch, embed)\n            nn.LayerNorm(embed),\n            nn.Linear(embed, embed)\n        )\n        self.output = AdditiveMarginSoftmax(embed, n_spks)\n        print(f\"AM-Softmax config: margin={self.output.margin}, factor={self.output.factor}\")\n    def forward(self, mels, y=None):\n                                        # in:  (batch, seq, feat)\n        out = self.model(mels)          # out: (batch, n_spks)\n        spaced = self.output(out, y)        \n        raw = self.output(out, None)\n        return spaced, raw","metadata":{"id":"iXZ5B0EKJGs8","execution":{"iopub.status.busy":"2023-03-21T06:24:03.250915Z","iopub.execute_input":"2023-03-21T06:24:03.251685Z","iopub.status.idle":"2023-03-21T06:24:03.282465Z","shell.execute_reply.started":"2023-03-21T06:24:03.251602Z","shell.execute_reply":"2023-03-21T06:24:03.281473Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Learning rate schedule\n- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n- Previous works show that the warmup of learning rate is useful for training models with transformer architectures.\n- The warmup schedule\n  - Set learning rate to 0 in the beginning.\n  - The learning rate increases linearly from 0 to initial learning rate during warmup period.","metadata":{"id":"W7yX8JinM5Ly"}},{"cell_type":"code","source":"import math\n\nimport torch\nfrom torch.optim import Optimizer\nfrom torch.optim.lr_scheduler import LambdaLR\n\n\ndef get_cosine_schedule_with_warmup(\n    optimizer: Optimizer,\n    num_warmup_steps: int,\n    num_training_steps: int,\n    num_cycles: float = 0.5,\n    last_epoch: int = -1,\n):\n    \"\"\"\n    Create a schedule with a learning rate that decreases following the values of the cosine function between the\n    initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n    initial lr set in the optimizer.\n\n    Args:\n        optimizer (:class:`~torch.optim.Optimizer`):\n        The optimizer for which to schedule the learning rate.\n        num_warmup_steps (:obj:`int`):\n        The number of steps for the warmup phase.\n        num_training_steps (:obj:`int`):\n        The total number of training steps.\n        num_cycles (:obj:`float`, `optional`, defaults to 0.5):\n        The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n        following a half-cosine).\n        last_epoch (:obj:`int`, `optional`, defaults to -1):\n        The index of the last epoch when resuming training.\n\n    Return:\n        :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n    \"\"\"\n    def lr_lambda(current_step):\n        # Warmup\n        if current_step < num_warmup_steps:\n            return float(current_step) / float(max(1, num_warmup_steps))\n        # decadence\n        progress = float(current_step - num_warmup_steps) / float(\n            max(1, num_training_steps - num_warmup_steps)\n        )\n        return 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n\n    return LambdaLR(optimizer, lr_lambda, last_epoch)","metadata":{"id":"ykt0N1nVJJi2","execution":{"iopub.status.busy":"2023-03-21T06:24:03.284078Z","iopub.execute_input":"2023-03-21T06:24:03.284489Z","iopub.status.idle":"2023-03-21T06:24:03.295733Z","shell.execute_reply.started":"2023-03-21T06:24:03.284452Z","shell.execute_reply":"2023-03-21T06:24:03.294579Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model Function\n- Model forward function.","metadata":{"id":"-LN2XkteM_uH"}},{"cell_type":"code","source":"import torch\n\n\ndef model_fn(batch, model, criterion, device, training=False):\n    \"\"\"Forward a batch through the model.\"\"\"\n\n    mels, labels = batch\n    mels = mels.to(device)\n    labels = labels.to(device)\n\n    outs, raw = model(mels, labels)\n\n    if training:\n        loss = criterion(outs, labels)\n    else:\n        loss = criterion(raw, labels)\n\n    # Get the speaker id with highest probability.\n    preds = raw.argmax(1)\n    # Compute accuracy.\n    accuracy = torch.mean((preds == labels).float())\n\n    return loss, accuracy","metadata":{"id":"N-rr8529JMz0","execution":{"iopub.status.busy":"2023-03-21T06:24:03.297058Z","iopub.execute_input":"2023-03-21T06:24:03.297637Z","iopub.status.idle":"2023-03-21T06:24:03.307441Z","shell.execute_reply.started":"2023-03-21T06:24:03.297544Z","shell.execute_reply":"2023-03-21T06:24:03.306498Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Validate\n- Calculate accuracy of the validation set.","metadata":{"id":"cwM_xyOtNCI2"}},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\n\n\ndef valid(dataloader, model, criterion, device): \n    \"\"\"Validate on validation set.\"\"\"\n\n    model.eval()\n    running_loss = 0.0\n    running_accuracy = 0.0\n    pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\")\n\n    for i, batch in enumerate(dataloader):\n        with torch.no_grad():\n            loss, accuracy = model_fn(batch, model, criterion, device)\n            running_loss += loss.item()\n            running_accuracy += accuracy.item()\n\n        pbar.update(dataloader.batch_size)\n        pbar.set_postfix(\n            loss=f\"{running_loss / (i+1):.4f}\",\n            accuracy=f\"{running_accuracy / (i+1):.4f}\",\n        )\n\n    pbar.close()\n    model.train()\n\n    return running_accuracy / len(dataloader)","metadata":{"id":"YAiv6kpdJRTJ","execution":{"iopub.status.busy":"2023-03-21T06:24:03.308937Z","iopub.execute_input":"2023-03-21T06:24:03.309315Z","iopub.status.idle":"2023-03-21T06:24:03.319422Z","shell.execute_reply.started":"2023-03-21T06:24:03.309255Z","shell.execute_reply":"2023-03-21T06:24:03.318435Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Main function","metadata":{"id":"g6ne9G-eNEdG"}},{"cell_type":"code","source":"from tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader, random_split\n\n\ndef parse_args():\n    \"\"\"arguments\"\"\"\n    config = {\n        \"data_dir\": \"/kaggle/input/ml2022spring-hw4/Dataset\",\n        \"save_path\": \"model\",\n        \"batch_size\": 32,\n        \"n_workers\": 0,\n        \"valid_steps\": 2000,\n        \"warmup_steps\": 1000,\n        \"total_steps\": 70000,\n    }\n\n    return config\n\n\ndef main(\n    data_dir,\n    save_path,\n    batch_size,\n    n_workers,\n    valid_steps,\n    warmup_steps,\n    total_steps,\n):\n    \"\"\"Main function.\"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"[Info]: Use {device} now!\")\n\n    train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n    running_patch = 0\n    train_iterator = iter(train_loader[running_patch])\n    print(f\"[Info]: Finish loading data!\",flush = True)\n\n    model = [Classifier(n_spks=speaker_num).to(device) for i in range(kfold)]\n    criterion = nn.CrossEntropyLoss()\n    optimizer = [AdamW(model[i].parameters(), lr=1e-3) for i in range(kfold)]\n    scheduler = [get_cosine_schedule_with_warmup(optimizer[i], warmup_steps, total_steps) for i in range(kfold)]\n    print(f\"[Info]: Finish creating model!\",flush = True)\n\n    best_accuracy = [-1.0 for i in range(kfold)]\n\n    pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n\n    for step in range(total_steps):\n        # Get data\n        try:\n            batch = next(train_iterator)\n        except StopIteration:\n            running_patch = (running_patch + 1) % kfold\n            train_iterator = iter(train_loader[running_patch])\n            batch = next(train_iterator)\n        for i in range(kfold):\n            if i == running_patch:\n                continue\n            loss, accuracy = model_fn(batch, model[i], criterion, device, training=True)\n            batch_loss = loss.item()\n            batch_accuracy = accuracy.item()\n            loss.backward()\n            optimizer[i].step()\n            scheduler[i].step()\n            optimizer[i].zero_grad()\n\n        # Log\n        pbar.update()\n        pbar.set_postfix(\n            loss=f\"{batch_loss:.2f}\",\n            accuracy=f\"{batch_accuracy:.2f}\",\n            step=step + 1,\n            running_patch=running_patch\n        )\n\n        # Do validation\n        if (step + 1) % valid_steps == 0:\n            pbar.close()\n\n            for i in range(kfold):\n                valid_accuracy = valid(valid_loader[i], model[i], criterion, device)\n\n                # keep the best model\n                if valid_accuracy > best_accuracy[i]:\n                    best_accuracy[i] = valid_accuracy\n                    torch.save(model[i].state_dict(), f\"{save_path}_{i}.ckpt\")\n                    \n            print(best_accuracy)\n            pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n\n    pbar.close()\n\n\nif __name__ == \"__main__\":\n    main(**parse_args())","metadata":{"id":"Usv9s-CuJSG7","execution":{"iopub.status.busy":"2023-03-21T06:24:03.320982Z","iopub.execute_input":"2023-03-21T06:24:03.321469Z","iopub.status.idle":"2023-03-21T11:35:39.520986Z","shell.execute_reply.started":"2023-03-21T06:24:03.321405Z","shell.execute_reply":"2023-03-21T11:35:39.519905Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[Info]: Use cuda now!\ndataset configs: segment_len=512, p=0.95\n[Info]: Finish loading data!\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\n[Info]: Finish creating model!\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [11:06<00:00,  3.00 step/s, accuracy=0.53, loss=12.14, running_patch=1, step=2000]\nValid: 100% 7072/7083 [00:07<00:00, 898.71 uttr/s, accuracy=0.4337, loss=2.5714]\nValid: 100% 7072/7083 [00:08<00:00, 876.41 uttr/s, accuracy=0.4907, loss=2.2871]\nValid: 100% 7072/7083 [00:08<00:00, 871.94 uttr/s, accuracy=0.4104, loss=2.6835]\nValid: 100% 7072/7083 [00:08<00:00, 853.57 uttr/s, accuracy=0.4714, loss=2.4406]\nValid: 100% 7072/7083 [00:07<00:00, 894.08 uttr/s, accuracy=0.4941, loss=2.2681]\nValid: 100% 7072/7083 [00:08<00:00, 871.91 uttr/s, accuracy=0.4420, loss=2.5751]\nValid: 100% 7072/7083 [00:08<00:00, 871.21 uttr/s, accuracy=0.4726, loss=2.3596]\nValid: 100% 7072/7085 [00:08<00:00, 875.83 uttr/s, accuracy=0.4641, loss=2.4363]\n","output_type":"stream"},{"name":"stdout","text":"[0.4336821266968326, 0.4906674208144796, 0.41035067873303166, 0.4714366515837104, 0.4940610859728507, 0.44202488687782804, 0.4725678733031674, 0.46408371040723984]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.38 step/s, accuracy=0.78, loss=8.51, running_patch=2, step=4000] \nValid: 100% 7072/7083 [00:08<00:00, 858.34 uttr/s, accuracy=0.7040, loss=1.3173]\nValid: 100% 7072/7083 [00:07<00:00, 893.59 uttr/s, accuracy=0.7223, loss=1.2312]\nValid: 100% 7072/7083 [00:07<00:00, 889.08 uttr/s, accuracy=0.6739, loss=1.4515]\nValid: 100% 7072/7083 [00:08<00:00, 861.94 uttr/s, accuracy=0.7188, loss=1.2732]\nValid: 100% 7072/7083 [00:07<00:00, 893.99 uttr/s, accuracy=0.7288, loss=1.2325]\nValid: 100% 7072/7083 [00:08<00:00, 853.81 uttr/s, accuracy=0.6973, loss=1.3969]\nValid: 100% 7072/7083 [00:08<00:00, 880.65 uttr/s, accuracy=0.7149, loss=1.2646]\nValid: 100% 7072/7085 [00:08<00:00, 830.83 uttr/s, accuracy=0.7052, loss=1.3325]\n","output_type":"stream"},{"name":"stdout","text":"[0.7040441176470589, 0.7222850678733032, 0.6739253393665159, 0.71875, 0.728789592760181, 0.6972567873303167, 0.7149321266968326, 0.7051753393665159]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.37 step/s, accuracy=0.69, loss=8.82, running_patch=3, step=6000] \nValid: 100% 7072/7083 [00:09<00:00, 726.79 uttr/s, accuracy=0.7896, loss=0.9562]\nValid: 100% 7072/7083 [00:09<00:00, 721.34 uttr/s, accuracy=0.8042, loss=0.8702]\nValid: 100% 7072/7083 [00:10<00:00, 651.39 uttr/s, accuracy=0.7723, loss=1.0274]\nValid: 100% 7072/7083 [00:08<00:00, 882.56 uttr/s, accuracy=0.7834, loss=0.9683]\nValid: 100% 7072/7083 [00:10<00:00, 656.31 uttr/s, accuracy=0.7957, loss=0.9168]\nValid: 100% 7072/7083 [00:09<00:00, 766.61 uttr/s, accuracy=0.7791, loss=1.0088]\nValid: 100% 7072/7083 [00:10<00:00, 676.50 uttr/s, accuracy=0.7999, loss=0.8838]\nValid: 100% 7072/7085 [00:12<00:00, 571.92 uttr/s, accuracy=0.7787, loss=1.0140]\n","output_type":"stream"},{"name":"stdout","text":"[0.7895927601809954, 0.8041572398190046, 0.772341628959276, 0.7833710407239819, 0.7956730769230769, 0.7791289592760181, 0.7999151583710408, 0.7787047511312217]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:47<00:00,  4.28 step/s, accuracy=0.84, loss=5.98, running_patch=4, step=8000]\nValid: 100% 7072/7083 [00:08<00:00, 794.85 uttr/s, accuracy=0.8363, loss=0.7347]\nValid: 100% 7072/7083 [00:08<00:00, 872.71 uttr/s, accuracy=0.8531, loss=0.6647]\nValid: 100% 7072/7083 [00:08<00:00, 881.90 uttr/s, accuracy=0.8326, loss=0.7724]\nValid: 100% 7072/7083 [00:07<00:00, 899.98 uttr/s, accuracy=0.8320, loss=0.7900]\nValid: 100% 7072/7083 [00:08<00:00, 811.00 uttr/s, accuracy=0.8396, loss=0.7463]\nValid: 100% 7072/7083 [00:08<00:00, 880.11 uttr/s, accuracy=0.8241, loss=0.8221]\nValid: 100% 7072/7083 [00:08<00:00, 877.07 uttr/s, accuracy=0.8507, loss=0.6644]\nValid: 100% 7072/7085 [00:07<00:00, 892.96 uttr/s, accuracy=0.8347, loss=0.7659]\n","output_type":"stream"},{"name":"stdout","text":"[0.8362556561085973, 0.8530825791855203, 0.832579185520362, 0.8320135746606335, 0.8396493212669683, 0.8240950226244343, 0.8506787330316742, 0.8347002262443439]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:41<00:00,  4.33 step/s, accuracy=0.91, loss=4.35, running_patch=5, step=1e+4]\nValid: 100% 7072/7083 [00:08<00:00, 872.26 uttr/s, accuracy=0.8676, loss=0.5824]\nValid: 100% 7072/7083 [00:07<00:00, 909.58 uttr/s, accuracy=0.8818, loss=0.5546]\nValid: 100% 7072/7083 [00:08<00:00, 851.93 uttr/s, accuracy=0.8559, loss=0.6688]\nValid: 100% 7072/7083 [00:08<00:00, 879.09 uttr/s, accuracy=0.8616, loss=0.6456]\nValid: 100% 7072/7083 [00:07<00:00, 908.26 uttr/s, accuracy=0.8524, loss=0.6970]\nValid: 100% 7072/7083 [00:07<00:00, 903.91 uttr/s, accuracy=0.8558, loss=0.6906]\nValid: 100% 7072/7083 [00:08<00:00, 883.04 uttr/s, accuracy=0.8743, loss=0.5884]\nValid: 100% 7072/7085 [00:07<00:00, 888.82 uttr/s, accuracy=0.8641, loss=0.6402]\n","output_type":"stream"},{"name":"stdout","text":"[0.8676470588235294, 0.8817873303167421, 0.8559106334841629, 0.861566742081448, 0.8523755656108597, 0.8557692307692307, 0.8742929864253394, 0.8641119909502263]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.37 step/s, accuracy=0.88, loss=5.57, running_patch=6, step=12000]\nValid: 100% 7072/7083 [00:08<00:00, 873.63 uttr/s, accuracy=0.8839, loss=0.5303]\nValid: 100% 7072/7083 [00:08<00:00, 855.69 uttr/s, accuracy=0.8959, loss=0.4952]\nValid: 100% 7072/7083 [00:08<00:00, 864.60 uttr/s, accuracy=0.8790, loss=0.5680]\nValid: 100% 7072/7083 [00:07<00:00, 891.04 uttr/s, accuracy=0.8763, loss=0.5968]\nValid: 100% 7072/7083 [00:08<00:00, 849.51 uttr/s, accuracy=0.8794, loss=0.5677]\nValid: 100% 7072/7083 [00:08<00:00, 822.77 uttr/s, accuracy=0.8703, loss=0.6267]\nValid: 100% 7072/7083 [00:07<00:00, 901.88 uttr/s, accuracy=0.8901, loss=0.5089]\nValid: 100% 7072/7085 [00:07<00:00, 894.55 uttr/s, accuracy=0.8792, loss=0.5622]\n","output_type":"stream"},{"name":"stdout","text":"[0.883908371040724, 0.8959276018099548, 0.8789592760180995, 0.8762726244343891, 0.8793834841628959, 0.8703337104072398, 0.8901300904977375, 0.8792420814479638]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.38 step/s, accuracy=0.94, loss=2.99, running_patch=7, step=14000]\nValid: 100% 7072/7083 [00:07<00:00, 902.34 uttr/s, accuracy=0.8901, loss=0.5309]\nValid: 100% 7072/7083 [00:08<00:00, 879.87 uttr/s, accuracy=0.9048, loss=0.4639]\nValid: 100% 7072/7083 [00:08<00:00, 855.59 uttr/s, accuracy=0.8884, loss=0.5367]\nValid: 100% 7072/7083 [00:08<00:00, 881.49 uttr/s, accuracy=0.9027, loss=0.4697]\nValid: 100% 7072/7085 [00:07<00:00, 884.94 uttr/s, accuracy=0.8894, loss=0.5285]\n","output_type":"stream"},{"name":"stdout","text":"[0.8901300904977375, 0.9048359728506787, 0.888433257918552, 0.8889988687782805, 0.8881504524886877, 0.8737273755656109, 0.9027149321266968, 0.8894230769230769]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:49<00:00,  4.26 step/s, accuracy=1.00, loss=1.98, running_patch=0, step=16000]\nValid: 100% 7072/7083 [00:12<00:00, 588.59 uttr/s, accuracy=0.9005, loss=0.4911]\nValid: 100% 7072/7083 [00:09<00:00, 771.11 uttr/s, accuracy=0.9047, loss=0.4570]\nValid: 100% 7072/7083 [00:07<00:00, 896.30 uttr/s, accuracy=0.8956, loss=0.4961]\nValid: 100% 7072/7083 [00:08<00:00, 870.56 uttr/s, accuracy=0.8928, loss=0.5535]\nValid: 100% 7072/7083 [00:12<00:00, 576.98 uttr/s, accuracy=0.9054, loss=0.4801]\nValid: 100% 7072/7083 [00:08<00:00, 817.29 uttr/s, accuracy=0.8863, loss=0.5699]\nValid: 100% 7072/7083 [00:08<00:00, 875.10 uttr/s, accuracy=0.9118, loss=0.4279]\nValid: 100% 7072/7085 [00:08<00:00, 876.87 uttr/s, accuracy=0.9021, loss=0.4879]\n","output_type":"stream"},{"name":"stdout","text":"[0.9004524886877828, 0.9048359728506787, 0.8956447963800905, 0.892816742081448, 0.9054015837104072, 0.8863122171945701, 0.9117647058823529, 0.9021493212669683]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:36<00:00,  4.38 step/s, accuracy=1.00, loss=2.36, running_patch=1, step=18000]\nValid: 100% 7072/7083 [00:08<00:00, 862.18 uttr/s, accuracy=0.9094, loss=0.4407]\nValid: 100% 7072/7083 [00:07<00:00, 891.51 uttr/s, accuracy=0.9156, loss=0.4326]\nValid: 100% 7072/7083 [00:07<00:00, 884.21 uttr/s, accuracy=0.9062, loss=0.4476]\nValid: 100% 7072/7083 [00:07<00:00, 911.97 uttr/s, accuracy=0.9023, loss=0.5008]\nValid: 100% 7072/7083 [00:07<00:00, 890.08 uttr/s, accuracy=0.9071, loss=0.4789]\nValid: 100% 7072/7083 [00:07<00:00, 906.39 uttr/s, accuracy=0.8979, loss=0.5256]\nValid: 100% 7072/7083 [00:07<00:00, 888.60 uttr/s, accuracy=0.9133, loss=0.4276]\nValid: 100% 7072/7085 [00:07<00:00, 904.23 uttr/s, accuracy=0.9081, loss=0.4610]\n","output_type":"stream"},{"name":"stdout","text":"[0.9093608597285068, 0.9155825791855203, 0.90625, 0.9022907239819005, 0.9070984162895928, 0.8979072398190046, 0.9133201357466063, 0.9080882352941176]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:36<00:00,  4.38 step/s, accuracy=0.97, loss=1.86, running_patch=2, step=2e+4] \nValid: 100% 7072/7083 [00:07<00:00, 925.25 uttr/s, accuracy=0.9123, loss=0.4440]\nValid: 100% 7072/7083 [00:08<00:00, 880.07 uttr/s, accuracy=0.9156, loss=0.4137]\nValid: 100% 7072/7083 [00:08<00:00, 843.58 uttr/s, accuracy=0.9000, loss=0.4653]\nValid: 100% 7072/7083 [00:08<00:00, 863.58 uttr/s, accuracy=0.9089, loss=0.4643]\nValid: 100% 7072/7083 [00:07<00:00, 902.70 uttr/s, accuracy=0.9125, loss=0.4618]\nValid: 100% 7072/7083 [00:08<00:00, 879.75 uttr/s, accuracy=0.9096, loss=0.4682]\nValid: 100% 7072/7083 [00:07<00:00, 893.99 uttr/s, accuracy=0.9211, loss=0.4017]\nValid: 100% 7072/7085 [00:08<00:00, 868.39 uttr/s, accuracy=0.9115, loss=0.4519]\n","output_type":"stream"},{"name":"stdout","text":"[0.9123303167420814, 0.9155825791855203, 0.90625, 0.9089366515837104, 0.9124717194570136, 0.909643665158371, 0.9210972850678733, 0.9114819004524887]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:36<00:00,  4.38 step/s, accuracy=0.94, loss=2.20, running_patch=3, step=22000]\nValid: 100% 7072/7083 [00:07<00:00, 898.98 uttr/s, accuracy=0.9200, loss=0.4094]\nValid: 100% 7072/7083 [00:08<00:00, 873.41 uttr/s, accuracy=0.9208, loss=0.3971]\nValid: 100% 7072/7083 [00:07<00:00, 900.12 uttr/s, accuracy=0.9149, loss=0.4272]\nValid: 100% 7072/7083 [00:07<00:00, 902.09 uttr/s, accuracy=0.9023, loss=0.5056]\nValid: 100% 7072/7083 [00:08<00:00, 800.18 uttr/s, accuracy=0.9156, loss=0.4514]\nValid: 100% 7072/7083 [00:08<00:00, 882.91 uttr/s, accuracy=0.9089, loss=0.4613]\nValid: 100% 7072/7083 [00:07<00:00, 886.81 uttr/s, accuracy=0.9265, loss=0.3768]\nValid: 100% 7072/7085 [00:08<00:00, 878.31 uttr/s, accuracy=0.9181, loss=0.4357]\n","output_type":"stream"},{"name":"stdout","text":"[0.9199660633484162, 0.920814479638009, 0.9148755656108597, 0.9089366515837104, 0.9155825791855203, 0.909643665158371, 0.9264705882352942, 0.9181278280542986]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:44<00:00,  4.31 step/s, accuracy=1.00, loss=2.30, running_patch=4, step=24000]\nValid: 100% 7072/7083 [00:08<00:00, 865.33 uttr/s, accuracy=0.9186, loss=0.4281]\nValid: 100% 7072/7083 [00:09<00:00, 748.16 uttr/s, accuracy=0.9225, loss=0.3906]\nValid: 100% 7072/7083 [00:09<00:00, 749.83 uttr/s, accuracy=0.9136, loss=0.4250]\nValid: 100% 7072/7083 [00:08<00:00, 864.93 uttr/s, accuracy=0.9068, loss=0.4694]\nValid: 100% 7072/7083 [00:08<00:00, 857.27 uttr/s, accuracy=0.9142, loss=0.4577]\nValid: 100% 7072/7083 [00:08<00:00, 831.15 uttr/s, accuracy=0.9123, loss=0.4585]\nValid: 100% 7072/7083 [00:09<00:00, 754.40 uttr/s, accuracy=0.9280, loss=0.3795]\nValid: 100% 7072/7085 [00:10<00:00, 680.57 uttr/s, accuracy=0.9195, loss=0.4202]\n","output_type":"stream"},{"name":"stdout","text":"[0.9199660633484162, 0.9225113122171946, 0.9148755656108597, 0.9089366515837104, 0.9155825791855203, 0.9123303167420814, 0.9280260180995475, 0.9195418552036199]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:40<00:00,  4.34 step/s, accuracy=1.00, loss=1.69, running_patch=5, step=26000]\nValid: 100% 7072/7083 [00:08<00:00, 865.43 uttr/s, accuracy=0.9229, loss=0.4051]\nValid: 100% 7072/7083 [00:08<00:00, 802.90 uttr/s, accuracy=0.9299, loss=0.3639]\nValid: 100% 7072/7083 [00:07<00:00, 886.91 uttr/s, accuracy=0.9169, loss=0.4102]\nValid: 100% 7072/7083 [00:07<00:00, 899.68 uttr/s, accuracy=0.9214, loss=0.4175]\nValid: 100% 7072/7083 [00:07<00:00, 895.74 uttr/s, accuracy=0.9210, loss=0.4372]\nValid: 100% 7072/7083 [00:07<00:00, 902.31 uttr/s, accuracy=0.9170, loss=0.4454]\nValid: 100% 7072/7083 [00:08<00:00, 878.17 uttr/s, accuracy=0.9340, loss=0.3545]\nValid: 100% 7072/7085 [00:07<00:00, 913.33 uttr/s, accuracy=0.9294, loss=0.3861]\n","output_type":"stream"},{"name":"stdout","text":"[0.922935520361991, 0.9298642533936652, 0.9168552036199095, 0.9213800904977375, 0.9209558823529411, 0.9169966063348416, 0.9339649321266968, 0.9294400452488688]\n","output_type":"stream"},{"name":"stderr","text":"Valid: 100% 7072/7085 [00:08<00:00, 875.62 uttr/s, accuracy=0.9255, loss=0.4093]ing_patch=5, step=27755]\n","output_type":"stream"},{"name":"stdout","text":"[0.928591628959276, 0.9360859728506787, 0.9199660633484162, 0.9213800904977375, 0.9209558823529411, 0.9169966063348416, 0.9339649321266968, 0.9294400452488688]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.37 step/s, accuracy=0.97, loss=1.85, running_patch=7, step=3e+4] \nValid: 100% 7072/7083 [00:08<00:00, 872.64 uttr/s, accuracy=0.9296, loss=0.3828]\nValid: 100% 7072/7083 [00:08<00:00, 869.57 uttr/s, accuracy=0.9314, loss=0.3880]\nValid: 100% 7072/7083 [00:07<00:00, 901.72 uttr/s, accuracy=0.9290, loss=0.3795]\nValid: 100% 7072/7083 [00:08<00:00, 870.69 uttr/s, accuracy=0.9163, loss=0.4635]\nValid: 100% 7072/7083 [00:08<00:00, 856.36 uttr/s, accuracy=0.9253, loss=0.4236]\nValid: 100% 7072/7083 [00:08<00:00, 880.45 uttr/s, accuracy=0.9183, loss=0.4478]\nValid: 100% 7072/7083 [00:08<00:00, 877.27 uttr/s, accuracy=0.9347, loss=0.3562]\nValid: 100% 7072/7085 [00:08<00:00, 819.66 uttr/s, accuracy=0.9306, loss=0.3992]\n","output_type":"stream"},{"name":"stdout","text":"[0.9295814479638009, 0.9360859728506787, 0.9290158371040724, 0.9213800904977375, 0.9253393665158371, 0.9182692307692307, 0.9346719457013575, 0.9305712669683258]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.37 step/s, accuracy=1.00, loss=0.91, running_patch=0, step=32000]\nValid: 100% 7072/7083 [00:07<00:00, 905.91 uttr/s, accuracy=0.9316, loss=0.3732]\nValid: 100% 7072/7083 [00:07<00:00, 884.27 uttr/s, accuracy=0.9352, loss=0.3869]\nValid: 100% 7072/7083 [00:07<00:00, 897.06 uttr/s, accuracy=0.9286, loss=0.3834]\nValid: 100% 7072/7083 [00:08<00:00, 877.20 uttr/s, accuracy=0.9227, loss=0.4298]\nValid: 100% 7072/7083 [00:07<00:00, 909.02 uttr/s, accuracy=0.9260, loss=0.4256]\nValid: 100% 7072/7083 [00:07<00:00, 902.31 uttr/s, accuracy=0.9272, loss=0.4225]\nValid: 100% 7072/7083 [00:08<00:00, 826.13 uttr/s, accuracy=0.9389, loss=0.3455]\nValid: 100% 7072/7085 [00:08<00:00, 857.44 uttr/s, accuracy=0.9253, loss=0.4233]\n","output_type":"stream"},{"name":"stdout","text":"[0.9315610859728507, 0.9360859728506787, 0.9290158371040724, 0.9226527149321267, 0.9260463800904978, 0.9271776018099548, 0.9389140271493213, 0.9305712669683258]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:43<00:00,  4.31 step/s, accuracy=0.97, loss=1.17, running_patch=1, step=34000]\nValid: 100% 7072/7083 [00:08<00:00, 866.28 uttr/s, accuracy=0.9361, loss=0.3672]\nValid: 100% 7072/7083 [00:07<00:00, 897.77 uttr/s, accuracy=0.9345, loss=0.3734]\nValid: 100% 7072/7083 [00:07<00:00, 890.08 uttr/s, accuracy=0.9303, loss=0.3822]\nValid: 100% 7072/7083 [00:08<00:00, 876.78 uttr/s, accuracy=0.9280, loss=0.4129]\nValid: 100% 7072/7083 [00:08<00:00, 882.50 uttr/s, accuracy=0.9260, loss=0.4228]\nValid: 100% 7072/7083 [00:09<00:00, 779.02 uttr/s, accuracy=0.9333, loss=0.4083]\nValid: 100% 7072/7083 [00:07<00:00, 902.93 uttr/s, accuracy=0.9385, loss=0.3586]\nValid: 100% 7072/7085 [00:08<00:00, 871.61 uttr/s, accuracy=0.9307, loss=0.3953]\n","output_type":"stream"},{"name":"stdout","text":"[0.9360859728506787, 0.9360859728506787, 0.9302884615384616, 0.9280260180995475, 0.9260463800904978, 0.9332579185520362, 0.9389140271493213, 0.9307126696832579]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.37 step/s, accuracy=1.00, loss=0.58, running_patch=2, step=36000]\nValid: 100% 7072/7083 [00:08<00:00, 883.66 uttr/s, accuracy=0.9362, loss=0.3668]\nValid: 100% 7072/7083 [00:07<00:00, 885.34 uttr/s, accuracy=0.9359, loss=0.3742]\nValid: 100% 7072/7083 [00:08<00:00, 846.97 uttr/s, accuracy=0.9324, loss=0.3619]\nValid: 100% 7072/7083 [00:08<00:00, 836.63 uttr/s, accuracy=0.9292, loss=0.3978]\nValid: 100% 7072/7083 [00:08<00:00, 850.31 uttr/s, accuracy=0.9263, loss=0.4294]\nValid: 100% 7072/7083 [00:08<00:00, 830.36 uttr/s, accuracy=0.9310, loss=0.3955]\nValid: 100% 7072/7083 [00:08<00:00, 823.80 uttr/s, accuracy=0.9400, loss=0.3616]\nValid: 100% 7072/7085 [00:09<00:00, 712.87 uttr/s, accuracy=0.9340, loss=0.3820]\n","output_type":"stream"},{"name":"stdout","text":"[0.9362273755656109, 0.9360859728506787, 0.9324095022624435, 0.9291572398190046, 0.926329185520362, 0.9332579185520362, 0.9400452488687783, 0.9339649321266968]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:48<00:00,  4.27 step/s, accuracy=1.00, loss=0.47, running_patch=3, step=38000]\nValid: 100% 7072/7083 [00:08<00:00, 869.60 uttr/s, accuracy=0.9365, loss=0.3580]\nValid: 100% 7072/7083 [00:08<00:00, 879.54 uttr/s, accuracy=0.9350, loss=0.3949]\nValid: 100% 7072/7083 [00:08<00:00, 845.47 uttr/s, accuracy=0.9376, loss=0.3500]\nValid: 100% 7072/7083 [00:08<00:00, 807.30 uttr/s, accuracy=0.9330, loss=0.4012]\nValid: 100% 7072/7083 [00:11<00:00, 609.50 uttr/s, accuracy=0.9352, loss=0.3902]\nValid: 100% 7072/7083 [00:08<00:00, 807.97 uttr/s, accuracy=0.9344, loss=0.3936]\nValid: 100% 7072/7083 [00:08<00:00, 828.87 uttr/s, accuracy=0.9419, loss=0.3542]\nValid: 100% 7072/7085 [00:08<00:00, 833.28 uttr/s, accuracy=0.9310, loss=0.4042]\n","output_type":"stream"},{"name":"stdout","text":"[0.9365101809954751, 0.9360859728506787, 0.9376414027149321, 0.932975113122172, 0.935237556561086, 0.9343891402714932, 0.9418834841628959, 0.9339649321266968]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [08:09<00:00,  4.09 step/s, accuracy=1.00, loss=0.68, running_patch=4, step=4e+4] \nValid: 100% 7072/7083 [00:08<00:00, 834.11 uttr/s, accuracy=0.9345, loss=0.3853]\nValid: 100% 7072/7083 [00:08<00:00, 870.31 uttr/s, accuracy=0.9416, loss=0.3626]\nValid: 100% 7072/7083 [00:08<00:00, 877.61 uttr/s, accuracy=0.9364, loss=0.3761]\nValid: 100% 7072/7083 [00:08<00:00, 810.61 uttr/s, accuracy=0.9317, loss=0.3824]\nValid: 100% 7072/7083 [00:08<00:00, 859.02 uttr/s, accuracy=0.9331, loss=0.4092]\nValid: 100% 7072/7083 [00:15<00:00, 444.18 uttr/s, accuracy=0.9293, loss=0.4187]\nValid: 100% 7072/7083 [00:09<00:00, 708.03 uttr/s, accuracy=0.9432, loss=0.3638]\nValid: 100% 7072/7085 [00:08<00:00, 840.01 uttr/s, accuracy=0.9348, loss=0.3735]\n","output_type":"stream"},{"name":"stdout","text":"[0.9365101809954751, 0.9416006787330317, 0.9376414027149321, 0.932975113122172, 0.935237556561086, 0.9343891402714932, 0.943156108597285, 0.9348133484162896]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.37 step/s, accuracy=0.97, loss=1.08, running_patch=6, step=42000]\nValid: 100% 7072/7083 [00:08<00:00, 823.14 uttr/s, accuracy=0.9409, loss=0.3684]\nValid: 100% 7072/7083 [00:09<00:00, 762.06 uttr/s, accuracy=0.9417, loss=0.3615]\nValid: 100% 7072/7083 [00:08<00:00, 800.79 uttr/s, accuracy=0.9379, loss=0.3430]\nValid: 100% 7072/7083 [00:08<00:00, 792.63 uttr/s, accuracy=0.9344, loss=0.3902]\nValid: 100% 7072/7083 [00:08<00:00, 855.87 uttr/s, accuracy=0.9320, loss=0.4204]\nValid: 100% 7072/7083 [00:07<00:00, 892.68 uttr/s, accuracy=0.9331, loss=0.4147]\nValid: 100% 7072/7083 [00:08<00:00, 879.22 uttr/s, accuracy=0.9446, loss=0.3529]\nValid: 100% 7072/7085 [00:08<00:00, 854.65 uttr/s, accuracy=0.9409, loss=0.3506]\n","output_type":"stream"},{"name":"stdout","text":"[0.940893665158371, 0.9417420814479638, 0.9379242081447964, 0.9343891402714932, 0.935237556561086, 0.9343891402714932, 0.9445701357466063, 0.940893665158371]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:35<00:00,  4.39 step/s, accuracy=0.97, loss=0.76, running_patch=7, step=44000]\nValid: 100% 7072/7083 [00:07<00:00, 899.85 uttr/s, accuracy=0.9422, loss=0.3544]\nValid: 100% 7072/7083 [00:08<00:00, 823.17 uttr/s, accuracy=0.9456, loss=0.3456]\nValid: 100% 7072/7083 [00:07<00:00, 887.92 uttr/s, accuracy=0.9423, loss=0.3436]\nValid: 100% 7072/7083 [00:08<00:00, 872.99 uttr/s, accuracy=0.9344, loss=0.4095]\nValid: 100% 7072/7083 [00:07<00:00, 905.92 uttr/s, accuracy=0.9365, loss=0.4155]\nValid: 100% 7072/7083 [00:08<00:00, 880.84 uttr/s, accuracy=0.9361, loss=0.4158]\nValid: 100% 7072/7083 [00:07<00:00, 898.36 uttr/s, accuracy=0.9444, loss=0.3631]\nValid: 100% 7072/7085 [00:08<00:00, 878.13 uttr/s, accuracy=0.9389, loss=0.3716]\n","output_type":"stream"},{"name":"stdout","text":"[0.9421662895927602, 0.9455599547511312, 0.9423076923076923, 0.9343891402714932, 0.9365101809954751, 0.9360859728506787, 0.9445701357466063, 0.940893665158371]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.37 step/s, accuracy=1.00, loss=0.23, running_patch=0, step=46000]\nValid: 100% 7072/7083 [00:08<00:00, 874.93 uttr/s, accuracy=0.9447, loss=0.3406]\nValid: 100% 7072/7083 [00:08<00:00, 857.39 uttr/s, accuracy=0.9419, loss=0.3661]\nValid: 100% 7072/7083 [00:07<00:00, 893.19 uttr/s, accuracy=0.9439, loss=0.3384]\nValid: 100% 7072/7083 [00:08<00:00, 872.63 uttr/s, accuracy=0.9365, loss=0.4026]\nValid: 100% 7072/7083 [00:07<00:00, 900.23 uttr/s, accuracy=0.9388, loss=0.4154]\nValid: 100% 7072/7083 [00:08<00:00, 832.78 uttr/s, accuracy=0.9385, loss=0.4031]\nValid: 100% 7072/7083 [00:08<00:00, 855.25 uttr/s, accuracy=0.9454, loss=0.3556]\nValid: 100% 7072/7085 [00:08<00:00, 827.71 uttr/s, accuracy=0.9400, loss=0.3899]\n","output_type":"stream"},{"name":"stdout","text":"[0.9447115384615384, 0.9455599547511312, 0.9438631221719457, 0.9365101809954751, 0.9387726244343891, 0.9384898190045249, 0.9454185520361991, 0.940893665158371]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:40<00:00,  4.35 step/s, accuracy=1.00, loss=0.52, running_patch=1, step=48000]\nValid: 100% 7072/7083 [00:07<00:00, 911.72 uttr/s, accuracy=0.9454, loss=0.3464]\nValid: 100% 7072/7083 [00:07<00:00, 884.55 uttr/s, accuracy=0.9426, loss=0.3792]\nValid: 100% 7072/7083 [00:08<00:00, 865.96 uttr/s, accuracy=0.9444, loss=0.3374]\nValid: 100% 7072/7083 [00:08<00:00, 871.80 uttr/s, accuracy=0.9395, loss=0.3901]\nValid: 100% 7072/7083 [00:07<00:00, 906.80 uttr/s, accuracy=0.9399, loss=0.3856]\nValid: 100% 7072/7083 [00:07<00:00, 894.65 uttr/s, accuracy=0.9359, loss=0.3967]\nValid: 100% 7072/7083 [00:07<00:00, 894.30 uttr/s, accuracy=0.9463, loss=0.3468]\nValid: 100% 7072/7085 [00:08<00:00, 868.21 uttr/s, accuracy=0.9430, loss=0.3694]\n","output_type":"stream"},{"name":"stdout","text":"[0.9454185520361991, 0.9455599547511312, 0.9444287330316742, 0.9394796380090498, 0.9399038461538461, 0.9384898190045249, 0.9462669683257918, 0.9430147058823529]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:36<00:00,  4.38 step/s, accuracy=1.00, loss=0.56, running_patch=2, step=5e+4] \nValid: 100% 7072/7083 [00:07<00:00, 909.39 uttr/s, accuracy=0.9453, loss=0.3531]\nValid: 100% 7072/7083 [00:08<00:00, 880.80 uttr/s, accuracy=0.9440, loss=0.3489]\nValid: 100% 7072/7083 [00:08<00:00, 865.91 uttr/s, accuracy=0.9427, loss=0.3497]\nValid: 100% 7072/7083 [00:07<00:00, 900.81 uttr/s, accuracy=0.9415, loss=0.3842]\nValid: 100% 7072/7083 [00:07<00:00, 891.48 uttr/s, accuracy=0.9427, loss=0.3857]\nValid: 100% 7072/7083 [00:08<00:00, 881.23 uttr/s, accuracy=0.9419, loss=0.3912]\nValid: 100% 7072/7083 [00:08<00:00, 882.00 uttr/s, accuracy=0.9501, loss=0.3327]\nValid: 100% 7072/7085 [00:07<00:00, 901.21 uttr/s, accuracy=0.9430, loss=0.3666]\n","output_type":"stream"},{"name":"stdout","text":"[0.9454185520361991, 0.9455599547511312, 0.9444287330316742, 0.9414592760180995, 0.9427319004524887, 0.9418834841628959, 0.9500848416289592, 0.9430147058823529]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:35<00:00,  4.39 step/s, accuracy=1.00, loss=0.10, running_patch=3, step=52000]\nValid: 100% 7072/7083 [00:08<00:00, 862.52 uttr/s, accuracy=0.9443, loss=0.3435]\nValid: 100% 7072/7083 [00:07<00:00, 906.28 uttr/s, accuracy=0.9487, loss=0.3485]\nValid: 100% 7072/7083 [00:07<00:00, 899.40 uttr/s, accuracy=0.9456, loss=0.3256]\nValid: 100% 7072/7083 [00:07<00:00, 898.37 uttr/s, accuracy=0.9367, loss=0.3902]\nValid: 100% 7072/7083 [00:08<00:00, 847.07 uttr/s, accuracy=0.9408, loss=0.3818]\nValid: 100% 7072/7083 [00:07<00:00, 898.26 uttr/s, accuracy=0.9420, loss=0.3732]\nValid: 100% 7072/7083 [00:07<00:00, 902.76 uttr/s, accuracy=0.9463, loss=0.3441]\nValid: 100% 7072/7085 [00:08<00:00, 883.58 uttr/s, accuracy=0.9424, loss=0.3770]\n","output_type":"stream"},{"name":"stdout","text":"[0.9454185520361991, 0.948670814479638, 0.9455599547511312, 0.9414592760180995, 0.9427319004524887, 0.942024886877828, 0.9500848416289592, 0.9430147058823529]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.37 step/s, accuracy=1.00, loss=0.66, running_patch=4, step=54000]\nValid: 100% 7072/7083 [00:07<00:00, 905.43 uttr/s, accuracy=0.9475, loss=0.3274]\nValid: 100% 7072/7083 [00:07<00:00, 890.94 uttr/s, accuracy=0.9504, loss=0.3374]\nValid: 100% 7072/7083 [00:08<00:00, 849.69 uttr/s, accuracy=0.9474, loss=0.3332]\nValid: 100% 7072/7083 [00:07<00:00, 909.68 uttr/s, accuracy=0.9430, loss=0.3670]\nValid: 100% 7072/7083 [00:07<00:00, 890.36 uttr/s, accuracy=0.9441, loss=0.3727]\nValid: 100% 7072/7083 [00:08<00:00, 870.99 uttr/s, accuracy=0.9412, loss=0.4050]\nValid: 100% 7072/7083 [00:08<00:00, 862.55 uttr/s, accuracy=0.9492, loss=0.3561]\nValid: 100% 7072/7085 [00:08<00:00, 860.35 uttr/s, accuracy=0.9457, loss=0.3507]\n","output_type":"stream"},{"name":"stdout","text":"[0.947539592760181, 0.9503676470588235, 0.9473981900452488, 0.9430147058823529, 0.9441459276018099, 0.942024886877828, 0.9500848416289592, 0.9457013574660633]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:35<00:00,  4.39 step/s, accuracy=1.00, loss=0.04, running_patch=5, step=56000]\nValid: 100% 7072/7083 [00:07<00:00, 923.72 uttr/s, accuracy=0.9446, loss=0.3565]\nValid: 100% 7072/7083 [00:08<00:00, 868.68 uttr/s, accuracy=0.9538, loss=0.3247]\nValid: 100% 7072/7083 [00:07<00:00, 889.56 uttr/s, accuracy=0.9474, loss=0.3295]\nValid: 100% 7072/7083 [00:07<00:00, 901.58 uttr/s, accuracy=0.9439, loss=0.3676]\nValid: 100% 7072/7083 [00:07<00:00, 906.83 uttr/s, accuracy=0.9461, loss=0.3807]\nValid: 100% 7072/7083 [00:08<00:00, 864.21 uttr/s, accuracy=0.9412, loss=0.3849]\nValid: 100% 7072/7083 [00:07<00:00, 900.84 uttr/s, accuracy=0.9504, loss=0.3264]\nValid: 100% 7072/7085 [00:07<00:00, 905.57 uttr/s, accuracy=0.9456, loss=0.3651]\n","output_type":"stream"},{"name":"stdout","text":"[0.947539592760181, 0.9537613122171946, 0.9473981900452488, 0.9438631221719457, 0.9461255656108597, 0.942024886877828, 0.9503676470588235, 0.9457013574660633]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:36<00:00,  4.38 step/s, accuracy=1.00, loss=0.04, running_patch=6, step=58000]\nValid: 100% 7072/7083 [00:07<00:00, 885.86 uttr/s, accuracy=0.9488, loss=0.3343]\nValid: 100% 7072/7083 [00:07<00:00, 906.96 uttr/s, accuracy=0.9501, loss=0.3431]\nValid: 100% 7072/7083 [00:07<00:00, 895.11 uttr/s, accuracy=0.9458, loss=0.3244]\nValid: 100% 7072/7083 [00:08<00:00, 870.60 uttr/s, accuracy=0.9457, loss=0.3681]\nValid: 100% 7072/7083 [00:08<00:00, 807.58 uttr/s, accuracy=0.9429, loss=0.3888]\nValid: 100% 7072/7083 [00:09<00:00, 785.61 uttr/s, accuracy=0.9426, loss=0.3963]\nValid: 100% 7072/7083 [00:09<00:00, 753.79 uttr/s, accuracy=0.9543, loss=0.3090]\nValid: 100% 7072/7085 [00:08<00:00, 824.40 uttr/s, accuracy=0.9491, loss=0.3504]\n","output_type":"stream"},{"name":"stdout","text":"[0.9488122171945701, 0.9537613122171946, 0.9473981900452488, 0.9457013574660633, 0.9461255656108597, 0.9425904977375565, 0.9543269230769231, 0.9490950226244343]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:37<00:00,  4.37 step/s, accuracy=1.00, loss=0.02, running_patch=7, step=6e+4] \nValid: 100% 7072/7083 [00:07<00:00, 930.61 uttr/s, accuracy=0.9485, loss=0.3347]\nValid: 100% 7072/7083 [00:08<00:00, 796.29 uttr/s, accuracy=0.9519, loss=0.3310]\nValid: 100% 7072/7083 [00:07<00:00, 891.93 uttr/s, accuracy=0.9491, loss=0.3188]\nValid: 100% 7072/7083 [00:07<00:00, 911.92 uttr/s, accuracy=0.9490, loss=0.3561]\nValid: 100% 7072/7083 [00:07<00:00, 915.91 uttr/s, accuracy=0.9481, loss=0.3564]\nValid: 100% 7072/7083 [00:08<00:00, 881.82 uttr/s, accuracy=0.9416, loss=0.3971]\nValid: 100% 7072/7083 [00:08<00:00, 826.78 uttr/s, accuracy=0.9526, loss=0.3330]\nValid: 100% 7072/7085 [00:07<00:00, 904.35 uttr/s, accuracy=0.9464, loss=0.3619]\n","output_type":"stream"},{"name":"stdout","text":"[0.9488122171945701, 0.9537613122171946, 0.9490950226244343, 0.9489536199095022, 0.9481052036199095, 0.9425904977375565, 0.9543269230769231, 0.9490950226244343]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:42<00:00,  4.33 step/s, accuracy=1.00, loss=0.17, running_patch=0, step=62000]\nValid: 100% 7072/7083 [00:11<00:00, 614.34 uttr/s, accuracy=0.9514, loss=0.3280]\nValid: 100% 7072/7083 [00:10<00:00, 682.64 uttr/s, accuracy=0.9522, loss=0.3403]\nValid: 100% 7072/7083 [00:08<00:00, 844.00 uttr/s, accuracy=0.9508, loss=0.3274]\nValid: 100% 7072/7083 [00:09<00:00, 731.65 uttr/s, accuracy=0.9474, loss=0.3637]\nValid: 100% 7072/7083 [00:09<00:00, 720.06 uttr/s, accuracy=0.9492, loss=0.3685]\nValid: 100% 7072/7083 [00:10<00:00, 655.03 uttr/s, accuracy=0.9440, loss=0.3905]\nValid: 100% 7072/7083 [00:08<00:00, 849.37 uttr/s, accuracy=0.9555, loss=0.3228]\nValid: 100% 7072/7085 [00:10<00:00, 695.13 uttr/s, accuracy=0.9471, loss=0.3521]\n","output_type":"stream"},{"name":"stdout","text":"[0.9513574660633484, 0.9537613122171946, 0.9507918552036199, 0.9489536199095022, 0.9492364253393665, 0.9440045248868778, 0.9554581447963801, 0.9490950226244343]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:47<00:00,  4.28 step/s, accuracy=1.00, loss=0.11, running_patch=1, step=64000]\nValid: 100% 7072/7083 [00:07<00:00, 892.28 uttr/s, accuracy=0.9542, loss=0.3096]\nValid: 100% 7072/7083 [00:08<00:00, 871.94 uttr/s, accuracy=0.9538, loss=0.3360]\nValid: 100% 7072/7083 [00:11<00:00, 638.85 uttr/s, accuracy=0.9484, loss=0.3179]\nValid: 100% 7072/7083 [00:07<00:00, 907.01 uttr/s, accuracy=0.9463, loss=0.3706]\nValid: 100% 7072/7083 [00:07<00:00, 902.54 uttr/s, accuracy=0.9477, loss=0.3739]\nValid: 100% 7072/7083 [00:08<00:00, 828.31 uttr/s, accuracy=0.9432, loss=0.3830]\nValid: 100% 7072/7083 [00:10<00:00, 706.20 uttr/s, accuracy=0.9552, loss=0.3271]\nValid: 100% 7072/7085 [00:08<00:00, 882.65 uttr/s, accuracy=0.9484, loss=0.3494]\n","output_type":"stream"},{"name":"stdout","text":"[0.954185520361991, 0.9537613122171946, 0.9507918552036199, 0.9489536199095022, 0.9492364253393665, 0.9440045248868778, 0.9554581447963801, 0.9490950226244343]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:38<00:00,  4.37 step/s, accuracy=1.00, loss=0.13, running_patch=2, step=66000]\nValid: 100% 7072/7083 [00:07<00:00, 892.98 uttr/s, accuracy=0.9512, loss=0.3285]\nValid: 100% 7072/7083 [00:08<00:00, 823.31 uttr/s, accuracy=0.9529, loss=0.3326]\nValid: 100% 7072/7083 [00:07<00:00, 916.00 uttr/s, accuracy=0.9509, loss=0.3212]\nValid: 100% 7072/7083 [00:08<00:00, 852.29 uttr/s, accuracy=0.9492, loss=0.3518]\nValid: 100% 7072/7083 [00:08<00:00, 869.01 uttr/s, accuracy=0.9492, loss=0.3506]\nValid: 100% 7072/7083 [00:07<00:00, 915.81 uttr/s, accuracy=0.9468, loss=0.3740]\nValid: 100% 7072/7083 [00:07<00:00, 909.12 uttr/s, accuracy=0.9569, loss=0.3085]\nValid: 100% 7072/7085 [00:08<00:00, 857.02 uttr/s, accuracy=0.9485, loss=0.3489]\n","output_type":"stream"},{"name":"stdout","text":"[0.954185520361991, 0.9537613122171946, 0.950933257918552, 0.9492364253393665, 0.9492364253393665, 0.9468325791855203, 0.9568721719457014, 0.9490950226244343]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:35<00:00,  4.39 step/s, accuracy=1.00, loss=0.02, running_patch=3, step=68000]\nValid: 100% 7072/7083 [00:07<00:00, 926.35 uttr/s, accuracy=0.9519, loss=0.3182]\nValid: 100% 7072/7083 [00:07<00:00, 921.38 uttr/s, accuracy=0.9522, loss=0.3337]\nValid: 100% 7072/7083 [00:07<00:00, 907.92 uttr/s, accuracy=0.9490, loss=0.3260]\nValid: 100% 7072/7083 [00:07<00:00, 896.48 uttr/s, accuracy=0.9497, loss=0.3451]\nValid: 100% 7072/7083 [00:07<00:00, 920.02 uttr/s, accuracy=0.9488, loss=0.3666]\nValid: 100% 7072/7083 [00:07<00:00, 920.22 uttr/s, accuracy=0.9468, loss=0.3724]\nValid: 100% 7072/7083 [00:07<00:00, 919.66 uttr/s, accuracy=0.9546, loss=0.3224]\nValid: 100% 7072/7085 [00:08<00:00, 869.12 uttr/s, accuracy=0.9502, loss=0.3476]\n","output_type":"stream"},{"name":"stdout","text":"[0.954185520361991, 0.9537613122171946, 0.950933257918552, 0.9496606334841629, 0.9492364253393665, 0.9468325791855203, 0.9568721719457014, 0.9502262443438914]\n","output_type":"stream"},{"name":"stderr","text":"Train: 100% 2000/2000 [07:44<00:00,  4.31 step/s, accuracy=1.00, loss=0.08, running_patch=4, step=7e+4] \nValid: 100% 7072/7083 [00:15<00:00, 449.81 uttr/s, accuracy=0.9491, loss=0.3314]\nValid: 100% 7072/7083 [00:14<00:00, 476.20 uttr/s, accuracy=0.9548, loss=0.3296]\nValid: 100% 7072/7083 [00:16<00:00, 434.84 uttr/s, accuracy=0.9490, loss=0.3336]\nValid: 100% 7072/7083 [00:11<00:00, 593.51 uttr/s, accuracy=0.9482, loss=0.3511]\nValid: 100% 7072/7083 [00:11<00:00, 618.81 uttr/s, accuracy=0.9512, loss=0.3515]\nValid: 100% 7072/7083 [00:16<00:00, 427.09 uttr/s, accuracy=0.9471, loss=0.3707]\nValid: 100% 7072/7083 [00:09<00:00, 756.37 uttr/s, accuracy=0.9559, loss=0.3168]\nValid: 100% 7072/7085 [00:08<00:00, 803.57 uttr/s, accuracy=0.9481, loss=0.3544]\n","output_type":"stream"},{"name":"stdout","text":"[0.954185520361991, 0.9547511312217195, 0.950933257918552, 0.9496606334841629, 0.9512160633484162, 0.9471153846153846, 0.9568721719457014, 0.9502262443438914]\n","output_type":"stream"},{"name":"stderr","text":"Train:   0% 0/2000 [00:00<?, ? step/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference\n\n## Dataset of inference","metadata":{"id":"NLatBYAhNNMx"}},{"cell_type":"code","source":"import os\nimport json\nimport torch\nfrom pathlib import Path\nfrom torch.utils.data import Dataset\n\n\nclass InferenceDataset(Dataset):\n    def __init__(self, data_dir):\n        testdata_path = Path(data_dir) / \"testdata.json\"\n        metadata = json.load(testdata_path.open())\n        self.data_dir = data_dir\n        self.data = metadata[\"utterances\"]\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        utterance = self.data[index]\n        feat_path = utterance[\"feature_path\"]\n        mel = torch.load(os.path.join(self.data_dir, feat_path))\n\n        return feat_path, mel\n\n\ndef inference_collate_batch(batch):\n    \"\"\"Collate a batch of data.\"\"\"\n    feat_paths, mels = zip(*batch)\n\n    return feat_paths, torch.stack(mels)","metadata":{"colab":{"background_save":true},"id":"efS4pCmAJXJH","execution":{"iopub.status.busy":"2023-03-21T11:35:39.522612Z","iopub.execute_input":"2023-03-21T11:35:39.523086Z","iopub.status.idle":"2023-03-21T11:35:39.531512Z","shell.execute_reply.started":"2023-03-21T11:35:39.523046Z","shell.execute_reply":"2023-03-21T11:35:39.530429Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Main funcrion of Inference","metadata":{"id":"tl0WnYwxNK_S"}},{"cell_type":"code","source":"import json\nimport csv\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\n\nimport torch\nfrom torch.utils.data import DataLoader\n\ndef parse_args():\n    \"\"\"arguments\"\"\"\n    config = {\n        \"data_dir\": \"/kaggle/input/ml2022spring-hw4/Dataset\",\n        \"model_path\": \"./model\",\n        \"output_path\": \"./output.csv\",\n    }\n\n    return config\n\n\ndef main(\n    data_dir,\n    model_path,\n    output_path,\n):\n    \"\"\"Main function.\"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"[Info]: Use {device} now!\")\n\n    mapping_path = Path(data_dir) / \"mapping.json\"\n    mapping = json.load(mapping_path.open())\n\n    dataset = InferenceDataset(data_dir)\n    dataloader = DataLoader(\n        dataset,\n        batch_size=1,\n        shuffle=False,\n        drop_last=False,\n        num_workers=0,\n        collate_fn=inference_collate_batch,\n    )\n    print(f\"[Info]: Finish loading data!\",flush = True)\n\n    speaker_num = len(mapping[\"id2speaker\"])\n    model = [Classifier(n_spks=speaker_num) for i in range(kfold)]\n    for i in range(kfold):\n        model[i].load_state_dict(torch.load(f\"{model_path}_{i}.ckpt\"))\n        model[i] = model[i].to(device)\n        model[i].eval()\n    print(f\"[Info]: Finish creating model!\",flush = True)\n\n    results = [[\"Id\", \"Category\"]]\n    for feat_paths, mels in tqdm(dataloader):\n        with torch.no_grad():\n            mels = mels.to(device)\n            summation = None\n            for md in model:\n                outs, _ = md(mels)\n                if summation == None:\n                    summation = outs\n                else:\n                    summation += outs\n            preds = summation.argmax(1).cpu().numpy()\n            for feat_path, pred in zip(feat_paths, preds):\n                results.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n\n    with open(output_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerows(results)\n\n\nif __name__ == \"__main__\":\n    main(**parse_args())","metadata":{"colab":{"background_save":true},"id":"i8SAbuXEJb2A","execution":{"iopub.status.busy":"2023-03-21T11:35:39.534886Z","iopub.execute_input":"2023-03-21T11:35:39.535460Z","iopub.status.idle":"2023-03-21T11:39:04.737172Z","shell.execute_reply.started":"2023-03-21T11:35:39.535424Z","shell.execute_reply":"2023-03-21T11:39:04.736259Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[Info]: Use cuda now!\n[Info]: Finish loading data!\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\nrunning config: embed=256, dropout=0.3\ndepwise_conv config: kernel_size=9\nAM-Softmax config: margin=0.35, factor=30\n[Info]: Finish creating model!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39d00fd65cc5482fbe17a091ff25df14"}},"metadata":{}}]}]}