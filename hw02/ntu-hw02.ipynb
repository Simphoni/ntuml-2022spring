{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 2 Phoneme Classification**\n\n* Slides: https://docs.google.com/presentation/d/1v6HkBWiJb8WNDcJ9_-2kwVstxUWml87b9CnA16Gdoio/edit?usp=sharing\n* Kaggle: https://www.kaggle.com/c/ml2022spring-hw2\n* Video: TBA\n","metadata":{"id":"OYlaRwNu7ojq"}},{"cell_type":"markdown","source":"### Preparing Data","metadata":{"id":"_L_4anls8Drv"}},{"cell_type":"markdown","source":"**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n\nA phoneme may span several frames and is dependent to past and future frames. \\\nHence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n\nFeel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)","metadata":{"id":"po4N3C-AWuWl"}},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.utils import rnn\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\ndef load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef preprocess_data(split, feat_dir, phone_path, train_ratio=0.8, train_val_seed=1337):\n    class_num = 41 # NOTE: pre-computed, should not need change\n    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n\n    label_dict = {}\n    if mode != 'test':\n      phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()\n\n      for line in phone_file:\n          line = line.strip('\\n').split(' ')\n          label_dict[line[0]] = [int(p) for p in line[1:]]\n\n    if split == 'train' or split == 'val':\n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.seed(train_val_seed)\n        random.shuffle(usage_list)\n        percent = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:]\n    elif split == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    seqlen = []\n    maxlen = 4000\n    X = torch.empty(4000, 1000, 39)\n    if mode != 'test':\n      y = torch.empty(4000, 1000, dtype=torch.long)\n\n    idx = 0\n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        cur_len = len(feat)\n        if mode != 'test':\n          label = torch.LongTensor(label_dict[fname])\n        X[idx, 0:cur_len, :] = feat\n        if mode != 'test':\n          y[idx, 0:cur_len] = label\n        seqlen.append(cur_len)\n        idx += 1\n\n    X = X[:idx, :]\n    if mode != 'test':\n      y = y[:idx]\n\n    print(f'[INFO] {split} set')\n    print(X.shape)\n    if mode != 'test':\n      print(y.shape)\n      return X, torch.tensor(seqlen, dtype=torch.int64), y\n    else:\n      return X, torch.tensor(seqlen, dtype=torch.int64)\n","metadata":{"id":"IJjLT8em-y9G","execution":{"iopub.status.busy":"2023-01-25T08:08:50.027849Z","iopub.execute_input":"2023-01-25T08:08:50.028357Z","iopub.status.idle":"2023-01-25T08:08:51.851335Z","shell.execute_reply.started":"2023-01-25T08:08:50.028275Z","shell.execute_reply":"2023-01-25T08:08:51.850249Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(f'DEVICE: {device}')","metadata":{"id":"CfRUEgC0GxUV","outputId":"f9804711-72b1-4717-896b-821a300cfe87","execution":{"iopub.status.busy":"2023-01-25T08:08:51.856864Z","iopub.execute_input":"2023-01-25T08:08:51.857882Z","iopub.status.idle":"2023-01-25T08:08:51.935122Z","shell.execute_reply.started":"2023-01-25T08:08:51.857844Z","shell.execute_reply":"2023-01-25T08:08:51.934061Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"DEVICE: cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Define Model","metadata":{"id":"IRqKNvNZwe3V"}},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(BasicBlock, self).__init__()\n\n        self.block = nn.Sequential(\n            nn.Linear(input_dim, output_dim),\n            nn.ReLU(),\n            nn.BatchNorm1d(output_dim),\n            nn.Dropout(p=0.2),\n        )\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\nclass interm(nn.Module):\n    def __init__(self, hidden_size, **kwargs):\n        super(interm, self).__init__(**kwargs)\n        self.hs = hidden_size\n    def forward(self, X):\n        data, seqlen = rnn.pad_packed_sequence(X[0], batch_first=True, total_length=1000)\n        idx = 0\n        for j in range(seqlen.shape[0]):\n            idx += seqlen[j]\n        dest = torch.empty(idx, self.hs, device=device)\n        idx = 0\n        for j in range(seqlen.shape[0]):\n            dest[idx:idx + seqlen[j],:] = data[j, 0:seqlen[j],:]\n            idx += seqlen[j]\n        return dest\n\nclass Classifier(nn.Module):\n    def __init__(self, output_dim=41):\n        super(Classifier, self).__init__()\n        hidden_size = 256\n        bi = True\n        dup = 2\n        self.fc = nn.Sequential(\n            nn.LSTM(39, hidden_size, dropout=0.2, num_layers=4, batch_first=True, bidirectional=bi),\n            interm(hidden_size * dup),\n            nn.BatchNorm1d(hidden_size * dup),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            BasicBlock(hidden_size * 2, 64),\n            nn.Linear(64, output_dim)\n        )\n\n    def forward(self, x):\n        x = self.fc(x)\n        return x","metadata":{"id":"Bg-GRd7ywdrL","execution":{"iopub.status.busy":"2023-01-25T08:32:07.302522Z","iopub.execute_input":"2023-01-25T08:32:07.303351Z","iopub.status.idle":"2023-01-25T08:32:07.316739Z","shell.execute_reply.started":"2023-01-25T08:32:07.303313Z","shell.execute_reply":"2023-01-25T08:32:07.315657Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Hyper-parameters","metadata":{"id":"TlIq8JeqvvHC"}},{"cell_type":"code","source":"# data prarameters\npad_length = 1000               # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\ntrain_ratio = 0.9               # the ratio of data used for training, the rest will be used for validation\n\n# training parameters\nseed = 114514                   # random seed\nbatch_size = 64                 # batch size\nnum_epoch = 50                  # the number of training epoch\nlearning_rate = 0.002            # learning rate\nmodel_path = './model.ckpt'     # the path where the checkpoint will be saved","metadata":{"id":"iIHn79Iav1ri","execution":{"iopub.status.busy":"2023-01-25T08:08:51.967820Z","iopub.execute_input":"2023-01-25T08:08:51.970692Z","iopub.status.idle":"2023-01-25T08:08:51.977325Z","shell.execute_reply.started":"2023-01-25T08:08:51.970663Z","shell.execute_reply":"2023-01-25T08:08:51.976286Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Prepare dataset and model","metadata":{"id":"IIUFRgG5yoDn"}},{"cell_type":"code","source":"import gc\n\n# preprocess data\ntrain_X, train_seqlen, train_y = preprocess_data(split='train', feat_dir='/kaggle/input/ml2022spring-hw2/libriphone/libriphone/feat', phone_path='/kaggle/input/ml2022spring-hw2/libriphone/libriphone', train_ratio=train_ratio)\nval_X, val_seqlen, val_y = preprocess_data(split='val', feat_dir='/kaggle/input/ml2022spring-hw2/libriphone/libriphone/feat', phone_path='/kaggle/input/ml2022spring-hw2/libriphone/libriphone', train_ratio=train_ratio)\n\n# get dataset\ntrain_set = TensorDataset(*(train_X.to(device), train_seqlen, train_y.to(device)))\nval_set = TensorDataset(*(val_X.to(device), val_seqlen, val_y.to(device)))\n\n# remove raw feature to save memory\ndel train_X, train_y, val_X, val_y\ngc.collect()\n\n# get dataloader\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)","metadata":{"id":"c1zI3v5jyrDn","outputId":"3ea2823a-83f3-42d9-ef05-2f2c002f9538","execution":{"iopub.status.busy":"2023-01-25T08:08:51.979090Z","iopub.execute_input":"2023-01-25T08:08:51.979876Z","iopub.status.idle":"2023-01-25T08:09:32.850756Z","shell.execute_reply.started":"2023-01-25T08:08:51.979839Z","shell.execute_reply":"2023-01-25T08:09:32.849762Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[Dataset] - # phone classes: 41, number of utterances for train: 3857\n","output_type":"stream"},{"name":"stderr","text":"3857it [00:32, 118.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] train set\ntorch.Size([3857, 1000, 39])\ntorch.Size([3857, 1000])\n[Dataset] - # phone classes: 41, number of utterances for val: 429\n","output_type":"stream"},{"name":"stderr","text":"429it [00:03, 114.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] val set\ntorch.Size([429, 1000, 39])\ntorch.Size([429, 1000])\n","output_type":"stream"}]},{"cell_type":"code","source":"#fix seed\ndef same_seeds(seed):\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)  \n    np.random.seed(seed)  \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True","metadata":{"id":"88xPiUnm0tAd","execution":{"iopub.status.busy":"2023-01-25T08:09:32.852323Z","iopub.execute_input":"2023-01-25T08:09:32.852710Z","iopub.status.idle":"2023-01-25T08:09:32.859672Z","shell.execute_reply.started":"2023-01-25T08:09:32.852668Z","shell.execute_reply":"2023-01-25T08:09:32.858582Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# fix random seed\nsame_seeds(seed)\n\n# create model, define a loss function, and optimizer\nmodel = Classifier().to(device)\ncriterion = nn.CrossEntropyLoss() \noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\nbest_acc = 0.0","metadata":{"id":"QTp3ZXg1yO9Y","execution":{"iopub.status.busy":"2023-01-25T08:32:12.868185Z","iopub.execute_input":"2023-01-25T08:32:12.868556Z","iopub.status.idle":"2023-01-25T08:32:12.929058Z","shell.execute_reply.started":"2023-01-25T08:32:12.868520Z","shell.execute_reply":"2023-01-25T08:32:12.928122Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"pwWH1KIqzxEr"}},{"cell_type":"code","source":"for epoch in range(num_epoch):\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    \n    # training\n    model.train() # set the model to training mode\n    train_items = 0\n    for i, batch in enumerate(tqdm(train_loader)):\n        features, seqlen, labels = batch\n        \n        optimizer.zero_grad() \n        outputs = model(rnn.pack_padded_sequence(features, seqlen, batch_first=True, enforce_sorted=False))\n        \n        idx = 0\n        dest = torch.empty(batch_size * 1000, dtype=torch.int64, device=device)\n        for j in range(seqlen.shape[0]):\n            dest[idx:idx + seqlen[j]] = labels[j, 0:seqlen[j]]\n            idx += seqlen[j]\n        labels = dest[:idx]\n        train_items += labels.shape[0]\n        \n        loss = criterion(outputs, labels)\n        loss.backward() \n        optimizer.step() \n        \n        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n        train_loss += loss.item()\n    \n    # validation\n    val_items = 0\n    if len(val_set) > 0:\n        model.eval() # set the model to evaluation mode\n        with torch.no_grad():\n            for i, batch in enumerate(tqdm(val_loader)):\n                features, seqlen, labels = batch\n                outputs = model(rnn.pack_padded_sequence(features, seqlen, batch_first=True, enforce_sorted=False))\n                \n                idx = 0\n                dest = torch.empty(batch_size * 1000, dtype=torch.int64, device=device)\n                for j in range(seqlen.shape[0]):\n                    dest[idx:idx + seqlen[j]] = labels[j, 0:seqlen[j]]\n                    idx += seqlen[j]\n                labels = dest[:idx];\n                val_items += labels.shape[0]\n                \n                loss = criterion(outputs, labels)\n                _, val_pred = torch.max(outputs, 1) \n                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n                val_loss += loss.item()\n\n            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n                epoch + 1, num_epoch, train_acc/train_items, train_loss/train_items, val_acc/val_items, val_loss/val_items\n            ))\n            print(val_acc)\n            # if the model improves, save a checkpoint at this epoch\n            if val_acc > best_acc:\n                best_acc = val_acc\n                torch.save(model.state_dict(), model_path)\n                print('saving model with acc {:.3f}'.format(best_acc/val_items))\n    else:\n        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n            epoch + 1, num_epoch, train_acc/train_items, train_loss/train_items\n        ))\n\n# if not validating, save the last epoch\nif len(val_set) == 0:\n    torch.save(model.state_dict(), model_path)\n    print('saving model at last epoch')\n","metadata":{"id":"CdMWsBs7zzNs","outputId":"17922ad2-a319-4253-8783-3e4939d0a7cf","execution":{"iopub.status.busy":"2023-01-25T09:27:50.758459Z","iopub.execute_input":"2023-01-25T09:27:50.758889Z","iopub.status.idle":"2023-01-25T10:02:38.415856Z","shell.execute_reply.started":"2023-01-25T09:27:50.758858Z","shell.execute_reply":"2023-01-25T10:02:38.414480Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[001/050] Train Acc: 0.962413 Loss: 0.000003 | Val Acc: 0.830570 loss: 0.000024\n219744.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[002/050] Train Acc: 0.966733 Loss: 0.000002 | Val Acc: 0.833167 loss: 0.000025\n220431.0\nsaving model with acc 0.833\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"[003/050] Train Acc: 0.969662 Loss: 0.000002 | Val Acc: 0.833091 loss: 0.000025\n220411.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"[004/050] Train Acc: 0.971677 Loss: 0.000002 | Val Acc: 0.833360 loss: 0.000026\n220482.0\nsaving model with acc 0.833\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"[005/050] Train Acc: 0.973658 Loss: 0.000002 | Val Acc: 0.834966 loss: 0.000027\n220907.0\nsaving model with acc 0.835\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"[006/050] Train Acc: 0.974902 Loss: 0.000002 | Val Acc: 0.834237 loss: 0.000027\n220714.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"[007/050] Train Acc: 0.974287 Loss: 0.000002 | Val Acc: 0.833432 loss: 0.000027\n220501.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"[008/050] Train Acc: 0.975288 Loss: 0.000002 | Val Acc: 0.833768 loss: 0.000027\n220590.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"[009/050] Train Acc: 0.976557 Loss: 0.000002 | Val Acc: 0.834966 loss: 0.000028\n220907.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"[010/050] Train Acc: 0.976712 Loss: 0.000002 | Val Acc: 0.832513 loss: 0.000028\n220258.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"[011/050] Train Acc: 0.976684 Loss: 0.000002 | Val Acc: 0.832211 loss: 0.000029\n220178.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"[012/050] Train Acc: 0.974395 Loss: 0.000002 | Val Acc: 0.829357 loss: 0.000028\n219423.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"[013/050] Train Acc: 0.972130 Loss: 0.000002 | Val Acc: 0.829814 loss: 0.000027\n219544.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"[014/050] Train Acc: 0.970153 Loss: 0.000002 | Val Acc: 0.826269 loss: 0.000027\n218606.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"[015/050] Train Acc: 0.960159 Loss: 0.000003 | Val Acc: 0.819946 loss: 0.000025\n216933.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  3.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"[016/050] Train Acc: 0.947571 Loss: 0.000004 | Val Acc: 0.815013 loss: 0.000024\n215628.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"[017/050] Train Acc: 0.941509 Loss: 0.000004 | Val Acc: 0.817784 loss: 0.000023\n216361.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[018/050] Train Acc: 0.952530 Loss: 0.000003 | Val Acc: 0.826220 loss: 0.000023\n218593.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"[019/050] Train Acc: 0.959366 Loss: 0.000003 | Val Acc: 0.826095 loss: 0.000025\n218560.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[020/050] Train Acc: 0.964555 Loss: 0.000003 | Val Acc: 0.828454 loss: 0.000025\n219184.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"[021/050] Train Acc: 0.963813 Loss: 0.000003 | Val Acc: 0.830533 loss: 0.000025\n219734.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"[022/050] Train Acc: 0.968857 Loss: 0.000002 | Val Acc: 0.831073 loss: 0.000026\n219877.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"[023/050] Train Acc: 0.969230 Loss: 0.000002 | Val Acc: 0.830646 loss: 0.000026\n219764.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"[024/050] Train Acc: 0.968137 Loss: 0.000002 | Val Acc: 0.831330 loss: 0.000026\n219945.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"[025/050] Train Acc: 0.972921 Loss: 0.000002 | Val Acc: 0.833027 loss: 0.000027\n220394.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"[026/050] Train Acc: 0.975544 Loss: 0.000002 | Val Acc: 0.833379 loss: 0.000027\n220487.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"[027/050] Train Acc: 0.978458 Loss: 0.000001 | Val Acc: 0.834611 loss: 0.000028\n220813.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"[028/050] Train Acc: 0.979925 Loss: 0.000001 | Val Acc: 0.834407 loss: 0.000029\n220759.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"[029/050] Train Acc: 0.980717 Loss: 0.000001 | Val Acc: 0.834176 loss: 0.000030\n220698.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"[030/050] Train Acc: 0.980885 Loss: 0.000001 | Val Acc: 0.833708 loss: 0.000030\n220574.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[031/050] Train Acc: 0.981421 Loss: 0.000001 | Val Acc: 0.834501 loss: 0.000030\n220784.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [01:03<00:00,  1.04s/it]\n100%|██████████| 7/7 [00:01<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"[032/050] Train Acc: 0.981481 Loss: 0.000001 | Val Acc: 0.832608 loss: 0.000030\n220283.0\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 2/61 [00:03<01:31,  1.55s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1669808422.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"del train_loader, val_loader\ngc.collect()","metadata":{"id":"ab33MxosWLmG","outputId":"911e8c9b-fc0f-4591-b0f6-311a1231c5e2","execution":{"iopub.status.busy":"2023-01-25T08:31:47.222447Z","iopub.status.idle":"2023-01-25T08:31:47.223014Z","shell.execute_reply.started":"2023-01-25T08:31:47.222768Z","shell.execute_reply":"2023-01-25T08:31:47.222791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing\nCreate a testing dataset, and load model from the saved checkpoint.","metadata":{"id":"1Hi7jTn3PX-m"}},{"cell_type":"code","source":"# load data\ntest_X, test_seqlen = preprocess_data(split='test', feat_dir='/kaggle/input/ml2022spring-hw2/libriphone/libriphone/feat', phone_path='/kaggle/input/ml2022spring-hw2/libriphone/libriphone')\ntest_set = TensorDataset(test_X, test_seqlen)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)","metadata":{"id":"VOG1Ou0PGrhc","outputId":"abaaa25b-a93c-49b0-d228-9eca1e2ab2e0","execution":{"iopub.status.busy":"2023-01-25T10:02:43.541590Z","iopub.execute_input":"2023-01-25T10:02:43.541936Z","iopub.status.idle":"2023-01-25T10:02:53.328001Z","shell.execute_reply.started":"2023-01-25T10:02:43.541908Z","shell.execute_reply":"2023-01-25T10:02:53.326972Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[Dataset] - # phone classes: 41, number of utterances for test: 1078\n","output_type":"stream"},{"name":"stderr","text":"1078it [00:09, 110.39it/s]","output_type":"stream"},{"name":"stdout","text":"[INFO] test set\ntorch.Size([1078, 1000, 39])\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# load model\nmodel = Classifier().to(device)\nmodel.load_state_dict(torch.load(model_path))","metadata":{"id":"ay0Fu8Ovkdad","outputId":"e5b20aa7-4d8b-43a9-e068-f5c89706a360","execution":{"iopub.status.busy":"2023-01-25T10:02:53.329964Z","iopub.execute_input":"2023-01-25T10:02:53.330908Z","iopub.status.idle":"2023-01-25T10:02:53.404736Z","shell.execute_reply.started":"2023-01-25T10:02:53.330869Z","shell.execute_reply":"2023-01-25T10:02:53.403544Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"Make prediction.","metadata":{"id":"zp-DV1p4r7Nz"}},{"cell_type":"code","source":"test_acc = 0.0\ntest_lengths = 0\npred = np.array([], dtype=np.int32)\n\nmodel.eval()\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(test_loader)):\n        features, seqlen = batch\n        features = features.to(device)\n\n        outputs = model(rnn.pack_padded_sequence(features, seqlen, batch_first=True, enforce_sorted=False))\n\n        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n","metadata":{"id":"84HU5GGjPqR0","outputId":"cebd6694-8f74-44ff-f922-96ca4385acb8","execution":{"iopub.status.busy":"2023-01-25T10:02:53.406283Z","iopub.execute_input":"2023-01-25T10:02:53.407774Z","iopub.status.idle":"2023-01-25T10:02:57.717739Z","shell.execute_reply.started":"2023-01-25T10:02:53.407738Z","shell.execute_reply":"2023-01-25T10:02:57.716743Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 17/17 [00:04<00:00,  3.95it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Write prediction to a CSV file.\n\nAfter finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle.","metadata":{"id":"wyZqy40Prz0v"}},{"cell_type":"code","source":"with open('prediction.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(pred):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"id":"GuljYSPHcZir","execution":{"iopub.status.busy":"2023-01-25T10:03:11.274212Z","iopub.execute_input":"2023-01-25T10:03:11.274565Z","iopub.status.idle":"2023-01-25T10:03:11.770460Z","shell.execute_reply.started":"2023-01-25T10:03:11.274531Z","shell.execute_reply":"2023-01-25T10:03:11.769482Z"},"trusted":true},"execution_count":19,"outputs":[]}]}